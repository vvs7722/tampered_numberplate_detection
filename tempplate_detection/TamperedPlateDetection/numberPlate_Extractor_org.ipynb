{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import imutils\n",
    "import easyocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in Image, Grayscale and Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('image5.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(cv2.cvtColor(gray, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply filter and find edges for localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfilter = cv2.bilateralFilter(gray, 11, 17, 17) #Noise reduction\n",
    "edged = cv2.Canny(bfilter, 30, 200) #Edge detection\n",
    "plt.imshow(cv2.cvtColor(edged, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find Contours and Apply Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = imutils.grab_contours(keypoints)\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = None\n",
    "for contour in contours:\n",
    "    approx = cv2.approxPolyDP(contour, 10, True)\n",
    "    if len(approx) == 4:\n",
    "        location = approx\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(gray.shape, np.uint8)\n",
    "new_image = cv2.drawContours(mask, [location], 0,255, -1)\n",
    "new_image = cv2.bitwise_and(img, img, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y) = np.where(mask==255)\n",
    "(x1, y1) = (np.min(x), np.min(y))\n",
    "(x2, y2) = (np.max(x), np.max(y))\n",
    "cropped_image = gray[x1:x2+1, y1:y2+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use Easy OCR To Read Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['en'])\n",
    "result = reader.readtext(cropped_image)\n",
    "text = \"\"\n",
    "\n",
    "for i in result:\n",
    "    text += i[1]\n",
    "\n",
    "if \"_\" in text:\n",
    "    text = text.replace(\"_\", \"\")\n",
    "if \" \" in text:\n",
    "    text=text.replace(\" \",\"\")\n",
    "text=text.upper()\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Render Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = result[0][-2]\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "res = cv2.putText(img, text=text, org=(approx[0][0][0], approx[1][0][1]+60), fontFace=font, fontScale=1, color=(0,255,0), thickness=2, lineType=cv2.LINE_AA)\n",
    "res = cv2.rectangle(img, tuple(approx[0][0]), tuple(approx[2][0]), (0,255,0),3)\n",
    "plt.imshow(cv2.cvtColor(res, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Removing spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=text.split(\" \")\n",
    "text=\"\".join(x)\n",
    "print(y)\n",
    "#Original data is stored in the form of dictionary\n",
    "data={\n",
    "    \"H982FKL\":\"Porsche 928\",\n",
    "    \"TS08JE6588\":\"Kia seltos\"\n",
    "}\n",
    "print(data[text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.Azure Custom Vision Api Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# API endpoint and details for image file\n",
    "endpoint_image = \"azure custom vision endpoint\"\n",
    "prediction_key = \"azure_customvision_predictionkey\"\n",
    "\n",
    "# Set headers\n",
    "headers_image = {\n",
    "    \"Prediction-Key\": prediction_key,\n",
    "    \"Content-Type\": \"application/octet-stream\",\n",
    "}\n",
    "\n",
    "# Replace with the path to the image file you want to analyze\n",
    "image_path = r\"image5.jpg\"\n",
    "\n",
    "# Read the image file as bytes\n",
    "image_data = open(image_path, \"rb\").read()\n",
    "\n",
    "# Make the prediction request for image file\n",
    "response_image = requests.post(endpoint_image, headers=headers_image, data=image_data)\n",
    "\n",
    "# Handle the response\n",
    "if response_image.status_code == 200:\n",
    "    results_image = response_image.json()\n",
    "    # Process the results as needed\n",
    "    highest_prediction_image = max(results_image['predictions'], key=lambda x: x['probability'])\n",
    "    print(f\"The highest probability prediction is: {highest_prediction_image['tagName']} with probability {highest_prediction_image['probability']:.2%}\")\n",
    "    if data[text] == highest_prediction_image['tagName']:\n",
    "        print(\"This is an Original Vehicle\")\n",
    "    else:\n",
    "        print(\"This is a Tampered/Fake Number plate\")\n",
    "else:\n",
    "    print(f\"Prediction failed with status code {response_image.status_code}\")\n",
    "    print(response_image.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
